import streamlit as st
import cv2
import numpy as np
from deepface import DeepFace
from PIL import Image
import pandas as pd # è¡¨ä½œæˆç”¨ã«è¿½åŠ 

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="é¡”ã®è¡¨æƒ…åˆ†æã‚¢ãƒ—ãƒª", layout="wide")

st.title("ğŸ˜Š é¡”ã®è¡¨æƒ…åˆ†æã‚·ã‚¹ãƒ†ãƒ  v2")
st.markdown("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚«ãƒ¡ãƒ©ã§æ’®å½±ã—ã¦æ„Ÿæƒ…ã‚’åˆ†æã—ã¾ã™ã€‚")

# æ—¥æœ¬èªå¤‰æ›ç”¨è¾æ›¸
EMOTION_TRANSLATION = {
    "angry": "æ€’ã‚Š",
    "disgust": "å«Œæ‚ª",
    "fear": "æã‚Œ",
    "happy": "å–œã³",
    "sad": "æ‚²ã—ã¿",
    "surprise": "é©šã",
    "neutral": "ç„¡è¡¨æƒ…"
}

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.header("è¨­å®š")
option = st.sidebar.selectbox(
    "å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ã‚«ãƒ¡ãƒ©ã§æ’®å½±")
)
min_confidence = st.sidebar.slider("æ¤œå‡ºæ„Ÿåº¦ï¼ˆæ ã®èª¿æ•´ç”¨ï¼‰", 0.0, 1.0, 0.5)

def analyze_emotion(image_np):
    try:
        img_cv = image_np.copy()
        
        # DeepFaceåˆ†æ
        results = DeepFace.analyze(img_cv, actions=['emotion'], enforce_detection=False)
        
        if not isinstance(results, list):
            results = [results]

        # çµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆï¼ˆUIè¡¨ç¤ºç”¨ï¼‰
        display_data = []

        for res in results:
            region = res['region']
            emotion_eng = res['dominant_emotion']
            scores = res['emotion']

            # é¡”é ˜åŸŸã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå°ã•ã™ãã‚‹èª¤æ¤œçŸ¥ãªã©ã‚’é˜²ãç°¡æ˜“å‡¦ç†ï¼‰
            if region['w'] < 20 or region['h'] < 20:
                continue

            # ç”»åƒã¸ã®æç”» (OpenCVã¯æ—¥æœ¬èªNGãªã®ã§è‹±èªã®ã¾ã¾ã€å°æ•°ç‚¹2æ¡ã«)
            x, y, w, h = region['x'], region['y'], region['w'], region['h']
            cv2.rectangle(img_cv, (x, y), (x+w, y+h), (0, 255, 0), 2)
            
            score_val = scores[emotion_eng]
            text = f"{emotion_eng} ({score_val:.2f}%)" # å°æ•°ç‚¹ç¬¬2ä½ã¾ã§
            cv2.putText(img_cv, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 
                        0.8, (36, 255, 12), 2)

            # UIè¡¨ç¤ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢ï¼ˆæ—¥æœ¬èªåŒ–ï¼‰
            formatted_scores = {}
            for k, v in scores.items():
                jp_key = EMOTION_TRANSLATION.get(k, k)
                formatted_scores[jp_key] = round(v, 2) # å€¤ã‚’ä¸¸ã‚ã‚‹

            display_data.append({
                "dominant_jp": EMOTION_TRANSLATION.get(emotion_eng, emotion_eng),
                "scores": formatted_scores
            })
        
        return img_cv, display_data

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        return image_np, []

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---

input_image = None

if option == "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=['jpg', 'png', 'jpeg'])
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        input_image = np.array(image.convert('RGB'))

elif option == "ã‚«ãƒ¡ãƒ©ã§æ’®å½±":
    camera_image = st.camera_input("ã‚«ãƒ¡ãƒ©ã§æ’®å½±ã—ã¦ãã ã•ã„")
    if camera_image is not None:
        image = Image.open(camera_image)
        input_image = np.array(image.convert('RGB'))

if input_image is not None:
    st.divider()
    
    col_input, col_btn = st.columns([1, 2])
    with col_input:
        st.image(input_image, caption="å…¥åŠ›ç”»åƒ", use_container_width=True)
    
    with col_btn:
        st.write("æº–å‚™ãŒã§ãã¾ã—ãŸã€‚ä¸‹ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
        analyze_btn = st.button("ğŸ” è¡¨æƒ…ã‚’åˆ†æã™ã‚‹", type="primary")

    if analyze_btn:
        with st.spinner('AIãŒåˆ†æä¸­...'):
            result_img, analysis_data = analyze_emotion(input_image)
            
            st.divider()
            
            if not analysis_data:
                st.warning("é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ç”»åƒã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
            else:
                # è¤‡æ•°äººã®é¡”ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã«å¯¾å¿œ
                for i, person_data in enumerate(analysis_data):
                    st.subheader(f"ğŸ‘¤ æ¤œå‡ºã•ã‚ŒãŸé¡” #{i+1}")
                    
                    # ã‚«ãƒ©ãƒ åˆ†ã‘: å·¦ã«ç”»åƒã€å³ã«ãƒ‡ãƒ¼ã‚¿
                    res_col1, res_col2 = st.columns(2)
                    
                    with res_col1:
                        # ç”»åƒè¡¨ç¤ºï¼ˆçµæœæç”»æ¸ˆã¿ï¼‰
                        st.image(result_img, caption="åˆ†æçµæœ", use_container_width=True)

                    with res_col2:
                        # æœ€ã‚‚å¼·ã„æ„Ÿæƒ…ã‚’ç›®ç«‹ãŸã›ã‚‹
                        dom_emotion = person_data["dominant_jp"]
                        st.metric(label="æœ€ã‚‚å¼·ã„æ„Ÿæƒ…", value=dom_emotion)

                        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
                        df = pd.DataFrame(
                            list(person_data["scores"].items()),
                            columns=["æ„Ÿæƒ…", "ã‚¹ã‚³ã‚¢ (%)"]
                        )
                        # ã‚¹ã‚³ã‚¢ãŒé«˜ã„é †ã«ä¸¦ã³æ›¿ãˆ
                        df = df.sort_values(by="ã‚¹ã‚³ã‚¢ (%)", ascending=False).reset_index(drop=True)

                        # è¡¨ã‚’è¡¨ç¤º
                        st.dataframe(
                            df, 
                            hide_index=True,
                            use_container_width=True,
                            column_config={
                                "ã‚¹ã‚³ã‚¢ (%)": st.column_config.ProgressColumn(
                                    "ç¢ºä¿¡åº¦",
                                    format="%.2f%%",
                                    min_value=0,
                                    max_value=100,
                                )
                            }
                        )
                        
                        # ã‚·ãƒ³ãƒ—ãƒ«ãªæ£’ã‚°ãƒ©ãƒ•ã‚‚è¡¨ç¤ºã—ãŸã„å ´åˆï¼ˆãŠå¥½ã¿ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆè§£é™¤ï¼‰
                        # st.bar_chart(df.set_index("æ„Ÿæƒ…"))