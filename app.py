import streamlit as st
import cv2
import numpy as np
from deepface import DeepFace
from PIL import Image
import tempfile
import os

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="é¡”ã®è¡¨æƒ…åˆ†æã‚¢ãƒ—ãƒª", layout="wide")

st.title("ğŸ˜Š é¡”ã®è¡¨æƒ…åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
st.write("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚«ãƒ¡ãƒ©ã§æ’®å½±ã—ã¦æ„Ÿæƒ…ã‚’åˆ†æã—ã¾ã™ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ¼ãƒ‰é¸æŠ
option = st.sidebar.selectbox(
    "å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ã‚«ãƒ¡ãƒ©ã§æ’®å½±")
)

def analyze_emotion(image_np):
    """
    ç”»åƒã‚’èª­ã¿è¾¼ã¿ã€DeepFaceã§æ„Ÿæƒ…åˆ†æã‚’è¡Œã„ã€
    é¡”ã®æ ã¨æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã‚’æç”»ã—ãŸç”»åƒã‚’è¿”ã™é–¢æ•°
    """
    try:
        # OpenCVå½¢å¼ã®ç”»åƒã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
        img_cv = image_np.copy()
        
        # DeepFaceã§åˆ†æ (backendsã¯opencvã‚„retinafaceãªã©é¸ã¹ã¾ã™ãŒã€opencvãŒæœ€é€Ÿ)
        # enforce_detection=Falseã«ã™ã‚‹ã¨ã€é¡”ãŒè¦‹ã¤ã‹ã‚‰ãªãã¦ã‚‚ã‚¨ãƒ©ãƒ¼ã«ãªã‚‰ãšå‡¦ç†ãŒé€²ã‚€
        results = DeepFace.analyze(img_cv, actions=['emotion'], enforce_detection=False)
        
        # çµæœã¯ãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã£ã¦ãã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚å¯¾å¿œ
        if not isinstance(results, list):
            results = [results]

        for res in results:
            # ä¿¡é ¼åº¦ãŒä½ã„ã€ã¾ãŸã¯é¡”é ˜åŸŸãŒæ¥µç«¯ã«å°ã•ã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹å‡¦ç†ã‚’å…¥ã‚Œã¦ã‚‚è‰¯ã„
            region = res['region']
            emotion = res['dominant_emotion']
            score = res['emotion'][emotion]

            # é¡”ã®åº§æ¨™
            x, y, w, h = region['x'], region['y'], region['w'], region['h']

            # çŸ©å½¢ã‚’æç”»
            cv2.rectangle(img_cv, (x, y), (x+w, y+h), (0, 255, 0), 2)

            # ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ„Ÿæƒ…ã¨ã‚¹ã‚³ã‚¢ï¼‰ã‚’æç”»
            text = f"{emotion} ({score:.1f}%)"
            cv2.putText(img_cv, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 
                        0.9, (36, 255, 12), 2)
        
        return img_cv, results

    except Exception as e:
        st.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return image_np, []

# ç”»åƒå…¥åŠ›ã®å‡¦ç†
input_image = None

if option == "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    uploaded_file = st.file_uploader("JPGã¾ãŸã¯PNGç”»åƒã‚’é¸æŠ", type=['jpg', 'png', 'jpeg'])
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        input_image = np.array(image.convert('RGB'))

elif option == "ã‚«ãƒ¡ãƒ©ã§æ’®å½±":
    camera_image = st.camera_input("ã‚«ãƒ¡ãƒ©ã§æ’®å½±ã—ã¦ãã ã•ã„")
    if camera_image is not None:
        image = Image.open(camera_image)
        input_image = np.array(image.convert('RGB'))

# åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
if input_image is not None:
    st.subheader("å…¥åŠ›ç”»åƒ")
    st.image(input_image, caption="å…ƒç”»åƒ", use_container_width=True)

    if st.button("è¡¨æƒ…ã‚’åˆ†æã™ã‚‹"):
        with st.spinner('åˆ†æä¸­...ï¼ˆåˆå›ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰'):
            result_img, analysis_data = analyze_emotion(input_image)
            
            # çµæœè¡¨ç¤ºã‚«ãƒ©ãƒ 
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("åˆ†æçµæœç”»åƒ")
                st.image(result_img, caption="æ¤œå‡ºçµæœ", use_container_width=True)
            
            with col2:
                st.subheader("è©³ç´°ãƒ‡ãƒ¼ã‚¿")
                if analysis_data:
                    # 1äººç›®ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿è©³ç´°è¡¨ç¤ºï¼ˆè¤‡æ•°äººå¯¾å¿œã‚‚å¯èƒ½ï¼‰
                    data = analysis_data[0]
                    st.write(f"**æ”¯é…çš„ãªæ„Ÿæƒ…:** {data['dominant_emotion']}")
                    st.write("**æ„Ÿæƒ…ã‚¹ã‚³ã‚¢:**")
                    st.json(data['emotion'])
                else:
                    st.warning("é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")